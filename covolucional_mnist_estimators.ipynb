{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting mnist/train-images-idx3-ubyte.gz\n",
      "Extracting mnist/train-labels-idx1-ubyte.gz\n",
      "Extracting mnist/t10k-images-idx3-ubyte.gz\n",
      "Extracting mnist/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets('mnist/', one_hot = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_treinamento = mnist.train.images\n",
    "y_treinamento = mnist.train.labels\n",
    "x_teste = mnist.test.images\n",
    "y_teste = mnist.test.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_treinamento = np.asarray(y_treinamento, dtype = np.int32)\n",
    "y_teste = np.asarray(y_teste, dtype = np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55000, 784)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_treinamento.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 784)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_teste.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 3, 4, ..., 5, 6, 8])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Classe: 7')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.imshow(x_treinamento[0].reshape((28,28)), cmap = 'gray')\n",
    "plt.title('Classe: ' + str(y_treinamento[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cria_rede(features, labels, mode):\n",
    "    #batch_size, largura, altura, canais -------v\n",
    "    entrada = tf.reshape(features['X'], [-1, 28, 28, 1])\n",
    "    \n",
    "    #recebe [batch_size, 28,28, 1]\n",
    "    #tretorna [batch_size, 28, 28, 32]\n",
    "    convolucao1 = tf.layers.conv2d(inputs = entrada, filters = 32, kernel_size = [5, 5], activation = tf.nn.relu, \n",
    "                                   padding = 'same')\n",
    "    \n",
    "    #recebe [batch_size, 28, 28, 32]\n",
    "    #retorna [batch_size, 14, 14, 32]\n",
    "    pooling1 = tf.layers.max_pooling2d(inputs = convolucao1, pool_size = [2,2], strides = 2)\n",
    "    \n",
    "    #recebe [batch_size, 14, 14, 32]\n",
    "    #retorna [batch_size, 14, 14, 64]\n",
    "    convolucao2 = tf.layers.conv2d(inputs = pooling1, filters = 64, kernel_size = [5, 5], activation = tf.nn.relu,\n",
    "                                  padding = 'same')\n",
    "    \n",
    "    #recebe [batch_size, 14, 14, 64]\n",
    "    #retorna [batch_size, 7, 7, 64]\n",
    "    pooling2 = tf.layers.max_pooling2d(inputs = convolucao2, pool_size = [2,2], strides = 2)\n",
    "    \n",
    "    #recebe [batch_size, 7, 7, 64]\n",
    "    #retorna [batch_size, 3236] --- um 'vetor'\n",
    "    flattening = tf.reshape(pooling2, [-1, 7 * 7 * 64])\n",
    "    \n",
    "    #entrada 3136 -> 1024[oculta] -> saida 10      [neuronios]\n",
    "    #recebe 3136 neuronios\n",
    "    #retorna [batch_size, 1024]\n",
    "    densa = tf.layers.dense(inputs = flattening, units = 1024, activation = tf.nn.relu)\n",
    "    \n",
    "    #dropout\n",
    "    dropout = tf.layers.dropout(inputs = densa, rate = 0.2, training = mode == tf.estimator.ModeKeys.TRAIN)\n",
    "    \n",
    "    #recebe [batch_size, 1024]\n",
    "    #retorna [batch_size , 10]\n",
    "    saida = tf.layers.dense(inputs = dropout, units = 10)\n",
    "    \n",
    "    # 0.2 0.2 0.6 = digito 2\n",
    "    previsoes = tf.argmax(saida, axis = 1)\n",
    "    \n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        return tf.estimator.EstimatorSpec(mode = mode, predictions = previsoes)\n",
    "    \n",
    "    erro = tf.losses.sparse_softmax_cross_entropy(labels = labels, logits = saida)\n",
    "    \n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        otimizador = tf.train.AdamOptimizer(learning_rate = 0.001)\n",
    "        treinamento = otimizador.minimize(erro, global_step = tf.train.get_global_step())\n",
    "        return tf.estimator.EstimatorSpec(mode = mode, loss = erro, train_op = treinamento)\n",
    "    \n",
    "    if mode == tf.estimator.ModeKeys.EVAL:\n",
    "        eval_metrics_ops = {'accuracy': tf.metrics.accuracy(labels = labels, predictions = previsoes)}\n",
    "        return tf.estimator.EstimatorSpec(mode = mode, loss = erro, eval_metric_ops = eval_metrics_ops)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\isac_\\AppData\\Local\\Temp\\tmpo5w4rbie\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'C:\\\\Users\\\\isac_\\\\AppData\\\\Local\\\\Temp\\\\tmpo5w4rbie', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x000001D1699B7D88>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "classificador = tf.estimator.Estimator(model_fn = cria_rede)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x000001D1698621C8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x000001D1698621C8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x000001D1698621C8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x000001D1698621C8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x000001D1696ECE08>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x000001D1696ECE08>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x000001D1696ECE08>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x000001D1696ECE08>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x000001D1699A4108>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x000001D1699A4108>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x000001D1699A4108>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x000001D1699A4108>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x000001D1692EDE08>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x000001D1692EDE08>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x000001D1692EDE08>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x000001D1692EDE08>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001D1692E6308>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001D1692E6308>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001D1692E6308>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001D1692E6308>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dropout.call of <tensorflow.python.layers.core.Dropout object at 0x000001D169B5DB48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dropout.call of <tensorflow.python.layers.core.Dropout object at 0x000001D169B5DB48>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dropout.call of <tensorflow.python.layers.core.Dropout object at 0x000001D169B5DB48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dropout.call of <tensorflow.python.layers.core.Dropout object at 0x000001D169B5DB48>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001D169978AC8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001D169978AC8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001D169978AC8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001D169978AC8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into C:\\Users\\isac_\\AppData\\Local\\Temp\\tmpo5w4rbie\\model.ckpt.\n",
      "INFO:tensorflow:loss = 2.293351, step = 1\n",
      "INFO:tensorflow:global_step/sec: 7.01964\n",
      "INFO:tensorflow:loss = 0.2069955, step = 101 (14.249 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 200 into C:\\Users\\isac_\\AppData\\Local\\Temp\\tmpo5w4rbie\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.06931086.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow_estimator.python.estimator.estimator.Estimator at 0x1d1699a7bc8>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "funcao_treinamento = tf.estimator.inputs.numpy_input_fn(x = {'X': x_treinamento}, y = y_treinamento,\n",
    "                                                        batch_size = 128, num_epochs = None, shuffle = True)\n",
    "classificador.train(input_fn = funcao_treinamento, steps = 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x000001D1699A7708>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x000001D1699A7708>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x000001D1699A7708>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x000001D1699A7708>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x000001D1699A7708>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x000001D1699A7708>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x000001D1699A7708>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x000001D1699A7708>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x000001D1699A7708>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x000001D1699A7708>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x000001D1699A7708>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x000001D1699A7708>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x000001D14DCF9908>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x000001D14DCF9908>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x000001D14DCF9908>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x000001D14DCF9908>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001D14DDCEDC8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001D14DDCEDC8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001D14DDCEDC8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001D14DDCEDC8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dropout.call of <tensorflow.python.layers.core.Dropout object at 0x000001D14DDA1AC8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dropout.call of <tensorflow.python.layers.core.Dropout object at 0x000001D14DDA1AC8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dropout.call of <tensorflow.python.layers.core.Dropout object at 0x000001D14DDA1AC8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dropout.call of <tensorflow.python.layers.core.Dropout object at 0x000001D14DDA1AC8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001D14DDA1AC8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001D14DDA1AC8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001D14DDA1AC8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001D14DDA1AC8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2020-02-14T13:36:53Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\isac_\\AppData\\Local\\Temp\\tmpo5w4rbie\\model.ckpt-200\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2020-02-14-13:36:56\n",
      "INFO:tensorflow:Saving dict for global step 200: accuracy = 0.9771, global_step = 200, loss = 0.071509406\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 200: C:\\Users\\isac_\\AppData\\Local\\Temp\\tmpo5w4rbie\\model.ckpt-200\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.9771, 'loss': 0.071509406, 'global_step': 200}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "funcao_teste = tf.estimator.inputs.numpy_input_fn(x = {'X': x_teste}, y = y_teste, num_epochs = 1,\n",
    "                                                      shuffle = False)\n",
    "resultados = classificador.evaluate(input_fn=funcao_teste)\n",
    "resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784,)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_imagem_teste = x_teste[10]\n",
    "x_imagem_teste.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 784)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_imagem_teste = x_imagem_teste.reshape(1, -1)\n",
    "x_imagem_teste.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x000001D14DBFB448>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x000001D14DBFB448>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x000001D14DBFB448>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x000001D14DBFB448>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x000001D1678B0C48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x000001D1678B0C48>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x000001D1678B0C48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x000001D1678B0C48>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x000001D14DA989C8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x000001D14DA989C8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x000001D14DA989C8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x000001D14DA989C8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x000001D14DA989C8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x000001D14DA989C8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x000001D14DA989C8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x000001D14DA989C8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001D14DB14C48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001D14DB14C48>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001D14DB14C48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001D14DB14C48>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dropout.call of <tensorflow.python.layers.core.Dropout object at 0x000001D1678640C8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dropout.call of <tensorflow.python.layers.core.Dropout object at 0x000001D1678640C8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dropout.call of <tensorflow.python.layers.core.Dropout object at 0x000001D1678640C8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dropout.call of <tensorflow.python.layers.core.Dropout object at 0x000001D1678640C8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001D1678640C8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001D1678640C8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001D1678640C8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001D1678640C8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\isac_\\AppData\\Local\\Temp\\tmpo5w4rbie\\model.ckpt-200\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    }
   ],
   "source": [
    "funcao_previsao = tf.estimator.inputs.numpy_input_fn(x = {'X': x_imagem_teste}, shuffle = False)\n",
    "pred = list(classificador.predict(input_fn = funcao_previsao))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Classe Prevista: 2')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_imagem_teste.reshape((28, 28)), cmap = 'gray')\n",
    "plt.title('Classe Prevista: ' + str(pred[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
